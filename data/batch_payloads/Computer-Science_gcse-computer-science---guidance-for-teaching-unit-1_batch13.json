{
  "subject": "Computer-Science",
  "filename": "gcse-computer-science---guidance-for-teaching-unit-1.md",
  "batch_index": 13,
  "issue_count": 10,
  "prompts": [
    "You are an expert proofreader and copy-editor, specialising in the final-pass review of documents for the Welsh Joint Education Committee (WJEC). You have an exceptional eye for detail, understanding that ever the smallest error can undermine the credibility of the entire document.\nYou possess specialist knowledge of Welsh educational terminology, WJEC-specific stylistic idioms, and common documentation formats.\nYour analysis must be uncompromisingly rigorous to catch all errors. Failure to do so will result in severe reputational damage to the WJEC. It will also disappoint the students and teachers who rely on the WJEC to provide accurate and reliable educational materials.\n<!--\n  Template context contract (provided by prompt_factory.py):\n    subject         -> string (e.g., \"Art-and-Design\")\n    filename        -> string (e.g., \"gcse-art-and-design---guidance-for-teaching.md\")\n    issue_table     -> Markdown string representing the batch table\n    page_context    -> iterable of { page_number: int, content: str }\n    retry_context?  -> optional note when re-asking the model (not currently used)\n-->\n\n## Document Under Review\n\nYou are reviewing **Computer-Science / gcse-computer-science---guidance-for-teaching-unit-1.md** from the WJEC Made-for-Wales 2025 GCSE documentation set. Treat this as a high-stakes proofread: every issue in the table below must be checked against the provided page excerpts.\n\n## Inputs\n\n1. **Issue Batch (Table):** Each row mirrors the original LanguageTool output for the current batch of issues.\n2. **Page Context:** The raw Markdown for each page referenced by this batch. Use it to confirm what the learner-facing document actually says.\n\n---\n\n## Task\n\nYour role is to act as a specialist linguistic validator, reassessing every row in the issue table. Do **not** rely on the LanguageTool `Type` or message alone\u2014use the page context, your WJEC domain knowledge, and authoritative sources to decide whether the suggestion is correct, optional, or a false alarm.\n\n---\n\n\n---\n\n### Guiding Principles & Authoritative Sources\n\n* **Validator's Stance:** Your primary duty is to protect linguistic quality. The burden of proof is on the **tool's suggestion**. Assume the original `[DOCUMENT TO REVIEW]` is correct unless the tool's suggestion definitively corrects an unambiguous error.\n* **Authoritative Sources:** When in doubt, especially for `Spelling Error` or `False Positive` decisions, you must consult authoritative sources.\n    * **UK English:** Oxford English Dictionary (OED), Collins Dictionary.\n    * **Welsh:** Geiriadur Prifysgol Cymru (GPC), Termau Cyd.\n    * **French:** Dictionnaire de l'Acad\u00e9mie Fran\u00e7aise, Larousse.\n    * **German:** Duden.\n    * **Spanish:** Diccionario de la lengua espa\u00f1ola (RAE).\n    * **Specialist Terms:** Refer to the `[DOCUMENT TO REVIEW]` for context.\n## Decision-Making Workflow\n\nFor **each issue** in the table:\n\n1. **Locate & Understand:** Use `context_from_tool` and the page excerpt to confirm the exact wording.\n2. **Evaluate:** Judge the reported problem against authoritative sources and WJEC conventions.\n3. **Categorise:** Choose one category from the list below (machine-readable enum values).\n4. **Score:** Provide a confidence score between 0\u2013100 (integers only).\n5. **Justify:** Supply a single concise sentence explaining the decision.\n\n\n## Output Format\n\nReturn a **single top-level JSON array** (no surrounding object, no page keys) and nothing else. Do not include backticks, commentary, or any text before or after the JSON. Each array element represents one issue from the table.\n\nIMPORTANT: the categoriser only needs to provide the LLM results for each issue \u2014 the detection fields are already known from the input CSV and are re-applied server-side. For each issue, return exactly the following fields and nothing more:\n\n- `issue_id`: integer \u2014 the issue identifier from the input CSV (auto-increment per-document)\n- `error_category`: one of the enum values listed in \"Error Categories\" above (e.g., `PARSING_ERROR`)\n- `confidence_score`: integer 0\u2013100 (if you prefer to provide 0\u20131 floats, the runner will convert them)\n- `reasoning`: single-sentence justification\n\nExample minimal output:\n```json\n[\n  {\n    \"issue_id\": 0,\n    \"error_category\": \"POSSIBLE_AMBIGUOUS_GRAMMATICAL_ERROR\",\n    \"confidence_score\": 70,\n    \"reasoning\": \"Comma improves clarity but omission is not a factual error.\"\n  },\n  {\n    \"issue_id\": 1,\n    \"error_category\": \"PARSING_ERROR\",\n    \"confidence_score\": 90,\n    \"reasoning\": \"Hyphenation required for compound adjective in UK English.\"\n  }\n]\n```\n\nEach error object **must** include only the four fields described above \u2014 `issue_id`, `error_category`, `confidence_score`, and `reasoning`. The runner will map `issue_id` back to the original detection row and attach the LLM fields to that issue.\n\nIMPORTANT: Always return a JSON array even for a single issue. For example, the array must be:\n\n```json\n[\n  {\n    \"issue_id\": 0,\n    \"error_category\": \"PARSING_ERROR\",\n    \"confidence_score\": 90,\n    \"reasoning\": \"Short single-sentence reason\"\n  }\n]\n```\n\nDo not return the single object without wrapping it in an array. Also ensure every string uses double-quotes and there are no trailing commas.\n\n---",
    "<!-- Document header (header, inputs, task) is defined in the system prompt\n\tto keep static role instructions separate from per-batch content. -->\n\n## Issue Batch\n\n### Page 66\n| issue_id | issue | highlighted_context |\n| --- | --- | --- |\n| 130 | len | ...t searchChar  set first = 0  set last = **len**(myArray[])- 1  repeat   set midpoint = ... |\n| 131 | myArray | ...archChar  set first = 0  set last = len(**myArray**[])- 1  repeat   set midpoint = (first +... |\n| 132 | searchChar | ...   set midpoint = (first + last)/2   if **searchChar** &lt; myArray[midpoint] then   set last = m... |\n| 133 | myArray | ...nt = (first + last)/2   if searchChar &lt; **myArray**[midpoint] then   set last = midpoint \u2013 ... |\n| 134 | myArray | ...t first = midpoint + 1   end if  until (**myArray**[midpoint] = searchChar)  output myArray... |\n| 135 | searchChar | ... 1   end if  until (myArray[midpoint] = **searchChar**)  output myArray[midpoint] ```  #### **... |\n| 136 | myArray | ...myArray[midpoint] = searchChar)  output **myArray**[midpoint] ```  #### **Characteristics o... |\n| 137 | passnum | ...eSort(bubbleList):   exchanges = True   **passnum** = len(bubbleList)-1   while passnum &gt; 0... |\n| 138 | len | ...leList):   exchanges = True   passnum = **len**(bubbleList)-1   while passnum &gt; 0 and e... |\n| 139 | bubbleList | ...st):   exchanges = True   passnum = len(**bubbleList**)-1   while passnum &gt; 0 and exchanges = ... |\n\nPage context:\n```markdown\n{66}------------------------------------------------\n\n```\nlast is integer \nmidpoint is integer\nmyArray[] is char[] \ninput searchChar \nset first = 0 \nset last = len(myArray[])- 1 \nrepeat \n set midpoint = (first + last)/2 \n if searchChar < myArray[midpoint] then \n set last = midpoint \u2013 1 \n else \n set first = midpoint + 1 \n end if \nuntil (myArray[midpoint] = searchChar) \noutput myArray[midpoint]\n```\n\n#### **Characteristics of sorting algorithms:**\n\n\u2022 **Bubble sort** is ideal for sorting data that is nearly sorted data structures. Bubble sorts will compare two elements next to each other. If they are not in correct order, they will then swap the two elements. It will then move onto next element in the data structure. Once it has reached the end of the file it will return to the start and repeat the process until all elements are sorted into the correct order.\n\n```\nDeclare BubbleSort(bubbleList): \n exchanges = True \n passnum = len(bubbleList)-1 \n while passnum > 0 and exchanges = True \n exchanges = False \n for i = 1 to n\n```\n\n\n```\n\n---\n\n\n---\n\n## Page Context\n\nReview each page excerpt before making decisions. Pages appear in ascending order and always include the page marker line.\n\n### Page 66\n```markdown\n{66}------------------------------------------------\n\n```\nlast is integer \nmidpoint is integer\nmyArray[] is char[] \ninput searchChar \nset first = 0 \nset last = len(myArray[])- 1 \nrepeat \n set midpoint = (first + last)/2 \n if searchChar < myArray[midpoint] then \n set last = midpoint \u2013 1 \n else \n set first = midpoint + 1 \n end if \nuntil (myArray[midpoint] = searchChar) \noutput myArray[midpoint]\n```\n\n#### **Characteristics of sorting algorithms:**\n\n\u2022 **Bubble sort** is ideal for sorting data that is nearly sorted data structures. Bubble sorts will compare two elements next to each other. If they are not in correct order, they will then swap the two elements. It will then move onto next element in the data structure. Once it has reached the end of the file it will return to the start and repeat the process until all elements are sorted into the correct order.\n\n```\nDeclare BubbleSort(bubbleList): \n exchanges = True \n passnum = len(bubbleList)-1 \n while passnum > 0 and exchanges = True \n exchanges = False \n for i = 1 to n\n```\n\n\n```\n\n\n---"
  ],
  "system": "You are an expert proofreader and copy-editor, specialising in the final-pass review of documents for the Welsh Joint Education Committee (WJEC). You have an exceptional eye for detail, understanding that ever the smallest error can undermine the credibility of the entire document.\nYou possess specialist knowledge of Welsh educational terminology, WJEC-specific stylistic idioms, and common documentation formats.\nYour analysis must be uncompromisingly rigorous to catch all errors. Failure to do so will result in severe reputational damage to the WJEC. It will also disappoint the students and teachers who rely on the WJEC to provide accurate and reliable educational materials.\n<!--\n  Template context contract (provided by prompt_factory.py):\n    subject         -> string (e.g., \"Art-and-Design\")\n    filename        -> string (e.g., \"gcse-art-and-design---guidance-for-teaching.md\")\n    issue_table     -> Markdown string representing the batch table\n    page_context    -> iterable of { page_number: int, content: str }\n    retry_context?  -> optional note when re-asking the model (not currently used)\n-->\n\n## Document Under Review\n\nYou are reviewing **Computer-Science / gcse-computer-science---guidance-for-teaching-unit-1.md** from the WJEC Made-for-Wales 2025 GCSE documentation set. Treat this as a high-stakes proofread: every issue in the table below must be checked against the provided page excerpts.\n\n## Inputs\n\n1. **Issue Batch (Table):** Each row mirrors the original LanguageTool output for the current batch of issues.\n2. **Page Context:** The raw Markdown for each page referenced by this batch. Use it to confirm what the learner-facing document actually says.\n\n---\n\n## Task\n\nYour role is to act as a specialist linguistic validator, reassessing every row in the issue table. Do **not** rely on the LanguageTool `Type` or message alone\u2014use the page context, your WJEC domain knowledge, and authoritative sources to decide whether the suggestion is correct, optional, or a false alarm.\n\n---\n\n\n---\n\n### Guiding Principles & Authoritative Sources\n\n* **Validator's Stance:** Your primary duty is to protect linguistic quality. The burden of proof is on the **tool's suggestion**. Assume the original `[DOCUMENT TO REVIEW]` is correct unless the tool's suggestion definitively corrects an unambiguous error.\n* **Authoritative Sources:** When in doubt, especially for `Spelling Error` or `False Positive` decisions, you must consult authoritative sources.\n    * **UK English:** Oxford English Dictionary (OED), Collins Dictionary.\n    * **Welsh:** Geiriadur Prifysgol Cymru (GPC), Termau Cyd.\n    * **French:** Dictionnaire de l'Acad\u00e9mie Fran\u00e7aise, Larousse.\n    * **German:** Duden.\n    * **Spanish:** Diccionario de la lengua espa\u00f1ola (RAE).\n    * **Specialist Terms:** Refer to the `[DOCUMENT TO REVIEW]` for context.\n## Decision-Making Workflow\n\nFor **each issue** in the table:\n\n1. **Locate & Understand:** Use `context_from_tool` and the page excerpt to confirm the exact wording.\n2. **Evaluate:** Judge the reported problem against authoritative sources and WJEC conventions.\n3. **Categorise:** Choose one category from the list below (machine-readable enum values).\n4. **Score:** Provide a confidence score between 0\u2013100 (integers only).\n5. **Justify:** Supply a single concise sentence explaining the decision.\n\n\n## Output Format\n\nReturn a **single top-level JSON array** (no surrounding object, no page keys) and nothing else. Do not include backticks, commentary, or any text before or after the JSON. Each array element represents one issue from the table.\n\nIMPORTANT: the categoriser only needs to provide the LLM results for each issue \u2014 the detection fields are already known from the input CSV and are re-applied server-side. For each issue, return exactly the following fields and nothing more:\n\n- `issue_id`: integer \u2014 the issue identifier from the input CSV (auto-increment per-document)\n- `error_category`: one of the enum values listed in \"Error Categories\" above (e.g., `PARSING_ERROR`)\n- `confidence_score`: integer 0\u2013100 (if you prefer to provide 0\u20131 floats, the runner will convert them)\n- `reasoning`: single-sentence justification\n\nExample minimal output:\n```json\n[\n  {\n    \"issue_id\": 0,\n    \"error_category\": \"POSSIBLE_AMBIGUOUS_GRAMMATICAL_ERROR\",\n    \"confidence_score\": 70,\n    \"reasoning\": \"Comma improves clarity but omission is not a factual error.\"\n  },\n  {\n    \"issue_id\": 1,\n    \"error_category\": \"PARSING_ERROR\",\n    \"confidence_score\": 90,\n    \"reasoning\": \"Hyphenation required for compound adjective in UK English.\"\n  }\n]\n```\n\nEach error object **must** include only the four fields described above \u2014 `issue_id`, `error_category`, `confidence_score`, and `reasoning`. The runner will map `issue_id` back to the original detection row and attach the LLM fields to that issue.\n\nIMPORTANT: Always return a JSON array even for a single issue. For example, the array must be:\n\n```json\n[\n  {\n    \"issue_id\": 0,\n    \"error_category\": \"PARSING_ERROR\",\n    \"confidence_score\": 90,\n    \"reasoning\": \"Short single-sentence reason\"\n  }\n]\n```\n\nDo not return the single object without wrapping it in an array. Also ensure every string uses double-quotes and there are no trailing commas.\n\n---",
  "user": [
    "<!-- Document header (header, inputs, task) is defined in the system prompt\n\tto keep static role instructions separate from per-batch content. -->\n\n## Issue Batch\n\n### Page 66\n| issue_id | issue | highlighted_context |\n| --- | --- | --- |\n| 130 | len | ...t searchChar  set first = 0  set last = **len**(myArray[])- 1  repeat   set midpoint = ... |\n| 131 | myArray | ...archChar  set first = 0  set last = len(**myArray**[])- 1  repeat   set midpoint = (first +... |\n| 132 | searchChar | ...   set midpoint = (first + last)/2   if **searchChar** &lt; myArray[midpoint] then   set last = m... |\n| 133 | myArray | ...nt = (first + last)/2   if searchChar &lt; **myArray**[midpoint] then   set last = midpoint \u2013 ... |\n| 134 | myArray | ...t first = midpoint + 1   end if  until (**myArray**[midpoint] = searchChar)  output myArray... |\n| 135 | searchChar | ... 1   end if  until (myArray[midpoint] = **searchChar**)  output myArray[midpoint] ```  #### **... |\n| 136 | myArray | ...myArray[midpoint] = searchChar)  output **myArray**[midpoint] ```  #### **Characteristics o... |\n| 137 | passnum | ...eSort(bubbleList):   exchanges = True   **passnum** = len(bubbleList)-1   while passnum &gt; 0... |\n| 138 | len | ...leList):   exchanges = True   passnum = **len**(bubbleList)-1   while passnum &gt; 0 and e... |\n| 139 | bubbleList | ...st):   exchanges = True   passnum = len(**bubbleList**)-1   while passnum &gt; 0 and exchanges = ... |\n\nPage context:\n```markdown\n{66}------------------------------------------------\n\n```\nlast is integer \nmidpoint is integer\nmyArray[] is char[] \ninput searchChar \nset first = 0 \nset last = len(myArray[])- 1 \nrepeat \n set midpoint = (first + last)/2 \n if searchChar < myArray[midpoint] then \n set last = midpoint \u2013 1 \n else \n set first = midpoint + 1 \n end if \nuntil (myArray[midpoint] = searchChar) \noutput myArray[midpoint]\n```\n\n#### **Characteristics of sorting algorithms:**\n\n\u2022 **Bubble sort** is ideal for sorting data that is nearly sorted data structures. Bubble sorts will compare two elements next to each other. If they are not in correct order, they will then swap the two elements. It will then move onto next element in the data structure. Once it has reached the end of the file it will return to the start and repeat the process until all elements are sorted into the correct order.\n\n```\nDeclare BubbleSort(bubbleList): \n exchanges = True \n passnum = len(bubbleList)-1 \n while passnum > 0 and exchanges = True \n exchanges = False \n for i = 1 to n\n```\n\n\n```\n\n---\n\n\n---\n\n## Page Context\n\nReview each page excerpt before making decisions. Pages appear in ascending order and always include the page marker line.\n\n### Page 66\n```markdown\n{66}------------------------------------------------\n\n```\nlast is integer \nmidpoint is integer\nmyArray[] is char[] \ninput searchChar \nset first = 0 \nset last = len(myArray[])- 1 \nrepeat \n set midpoint = (first + last)/2 \n if searchChar < myArray[midpoint] then \n set last = midpoint \u2013 1 \n else \n set first = midpoint + 1 \n end if \nuntil (myArray[midpoint] = searchChar) \noutput myArray[midpoint]\n```\n\n#### **Characteristics of sorting algorithms:**\n\n\u2022 **Bubble sort** is ideal for sorting data that is nearly sorted data structures. Bubble sorts will compare two elements next to each other. If they are not in correct order, they will then swap the two elements. It will then move onto next element in the data structure. Once it has reached the end of the file it will return to the start and repeat the process until all elements are sorted into the correct order.\n\n```\nDeclare BubbleSort(bubbleList): \n exchanges = True \n passnum = len(bubbleList)-1 \n while passnum > 0 and exchanges = True \n exchanges = False \n for i = 1 to n\n```\n\n\n```\n\n\n---"
  ]
}